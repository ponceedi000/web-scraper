# Web Scraper

**Author**: Ediberto Ponce
**Version**: 1.0.0

- [PR Link](https://github.com/ponceedi000/web-scraper/pull/1)

## Overview

It’s wonderful when someone has gone to the effort to expose their site’s data through an API.
But not everyone can (or wants to) do that.
No problem. Let’s code up a web scraper that can automate the process of manually using the site.

## Feature Tasks and Requirements
- Scrape a Wikipedia page and record which passages need citations.
- Your web scraper should report the number of citations needed.
- Your web scraper should identify those cases AND include the relevant passage.
  * E.g. Citation needed for “lorem spam and impsum eggs”
  * Consider the “relevant passage” to be the parent element that contains the passage, often a paragraph element.


## Architecture

- Python 3
- Pytest
- Poetry
- Requests
- BeautifulSoup


## Credit and Collaborations

- Brandon Mitzutani
- Alex Payne
- Connor Boyce


## Resources

- [Citation Hunt](https://citationhunt.toolforge.org/en?id=74244a1a&cat=3dded4f5)
- [Beautiful Soup: Build a Web Scraper With Python](https://realpython.com/beautiful-soup-web-scraper-python/#extract-attributes-from-html-elements)
- [Python New Line: How to add a new line](https://flexiple.com/python-new-line/#:~:text=In%20Python%2C%20the%20new%20line,displayed%20in%20a%20new%20line.)

## Name of feature: Count function 

- Estimate of time needed to complete: 1

- Start time: 1:30pm

- Finish time: 3:00pm

- Actual time needed to complete: 1 hour 30 min

## Name of feature: Report function

- Estimate of time needed to complete: 2

- Start time: 3:00pm

- Finish time: 4:15pm

- Actual time needed to complete: 1 hour 15 min

## Name of feature: User Acceptance Tests

- Estimate of time needed to complete: 1

- Start time: 4:15pm

- Finish time: 5:00pm

- Actual time needed to complete: 45 min